{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection Pipeline on UCS using Tensorflow 2.0\n",
    "\n",
    "This notebook focuses on implementing object detection as a Kubeflow pipeline on Cisco UCS by using Darknet which is a open-source neural network framework, YOLO (You Only Look Once) which is a real-time object detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Cisco Kubeflow starter pack repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH_NAME=\"dev\" #Provide git branch \"master\" or \"dev\"\n",
    "! git clone -b $BRANCH_NAME https://github.com/CiscoAI/cisco-kubeflow-starter-pack.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kfp==1.0.1 pillow==7.2.0 mlflow==1.13.1 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import yaml\n",
    "import calendar\n",
    "import requests\n",
    "import logging\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "#Kubeflow\n",
    "import kfp\n",
    "from kfp.aws import use_aws_secret\n",
    "import kfp.compiler as compiler\n",
    "\n",
    "#Kubernetes\n",
    "from kubernetes import client\n",
    "\n",
    "#Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pipeline components\n",
    "\n",
    "Declare the paths of respective YAML configuration files of each of the pipeline components, in order to load each component into a variable for pipeline execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='cisco-kubeflow-starter-pack/apps/computer-vision/object-detection/onprem/pipeline/components/v2/'\n",
    "component_root_train= path+'train/'\n",
    "component_root_tensorboard= path+'tensorboard/'\n",
    "component_root_inference= path+'inference/'\n",
    "\n",
    "train_op = kfp.components.load_component_from_file(os.path.join(component_root_train, 'component.yaml'))\n",
    "infer_op = kfp.components.load_component_from_file(os.path.join(component_root_inference, 'component.yaml'))\n",
    "tensorboard_op = kfp.components.load_component_from_file(os.path.join(component_root_tensorboard, 'component.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define volume claim & volume mount for storage during pipeline execution\n",
    "\n",
    "Persistent volume claim & volume mount is created for the purpose of storing entities such as dataset, model files, etc, and to share the stored resources between the various components of the pipeline during it's execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_pvc = client.V1PersistentVolumeClaimVolumeSource(claim_name='nfs')\n",
    "nfs_volume = client.V1Volume(name='nfs', persistent_volume_claim=nfs_pvc)\n",
    "nfs_volume_mount = client.V1VolumeMount(mount_path='/mnt/', name='nfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = str(calendar.timegm(time.gmtime()))\n",
    "def object_detection_pipeline():\n",
    "    # Defining Task for tensorboard\n",
    "    tf_tensorboard_task = tensorboard_op(timestamp=timestamp)\n",
    "    tf_tensorboard_task.add_volume(nfs_volume)\n",
    "    tf_tensorboard_task.add_volume_mount(nfs_volume_mount)\n",
    "    \n",
    "    # Defining Task for Model Training\n",
    "    tf_train_model_task = train_op(timestamp=timestamp)\n",
    "    tf_train_model_task.add_volume(nfs_volume)\n",
    "    tf_train_model_task.add_volume_mount(nfs_volume_mount) \n",
    "    tf_train_model_task.after(tf_tensorboard_task) \n",
    "    \n",
    "    #Defining Task for Infer training\n",
    "    tf_infer_model_task = infer_op(timestamp=timestamp)\n",
    "    tf_infer_model_task.add_volume(nfs_volume)\n",
    "    tf_infer_model_task.add_volume_mount(nfs_volume_mount) \n",
    "    tf_infer_model_task.after(tf_train_model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile pipeline function\n",
    "\n",
    "Compile the pipeline function to create a tar ball for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile pipeline\n",
    "try:\n",
    "    compiler.Compiler().compile(object_detection_pipeline, 'object-detection.tar.gz')\n",
    "except RuntimeError as err:\n",
    "    logging.debug(err)\n",
    "    logging.info(\"Argo workflow failed validation check but it can still be used to run experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/77521dfc-ff54-4f49-b526-7d581ea527e2\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kp_client = kfp.Client()\n",
    "EXPERIMENT_NAME = 'Object Detection'\n",
    "experiment = kp_client.create_experiment(name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pipeline parameters & run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/3915a701-9f4b-4114-b958-2442c87e8564\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_name = 'tensorflow-object-detection-'+timestamp\n",
    "\n",
    "# Execute pipeline\n",
    "run = kp_client.run_pipeline(experiment.id, run_name,'object-detection.tar.gz', \n",
    "                          params={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve current pipeline run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = str(run.id)\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_client.runs.delete_run(run_id)\n",
    "print(\"Pipeline run with run ID '%s' successfully deleted\"%run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
